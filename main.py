import nltk
import re
nltk.download('punkt')

from nltk.tokenize import word_tokenize
with open ('test2.txt') as fin:
    program_tokens = word_tokenize(fin.read())


## looking for my tokens
keywords = "float|int|double|auto|def"
punc = "({)|(})|(;)|\(\)|\(|\)"
ident = "^[a-zA-Z_]+[a-zA-Z0-9_]*"
symbols = "(-)|(=)|(\*)|(/)|(%)" 


## Runs through the list that I made of tokens and identify's them as a 
##
for token in program_tokens:
  if(re.findall(keywords,token)):
    print("<Keyword>", token)
  elif(re.findall(punc,token)):
    print("<Punctuator>", token)
  elif(re.findall(symbols, token)):
    print("<Symbol>", token)
  elif(re.findall(ident, token)):
    print("<Identifier>", token)


count = 0
## This is for checking the Program EBNF Grammer
if(re.findall(keywords,program_tokens[0]) and re.findall(ident,program_tokens[1])):
  count += 1


## This is for checking the Declare EBNF Grammer 
if(re.findall(keywords,program_tokens[3]) and re.findall(ident,program_tokens[4])):
  count += 1
else: print("Error missing keyword and identifier in header\nThe test program cannot be generated by the simple Demo Function BNF Grammer")
exit()


## This checks to see if the keywords equal to one or not. If not then the rest of the code 
## can't be generated by the BNF grammer, since there would be expersions with no keywords, but
## only Identifiers that haven't been declared yet 
sum = 0;
for token in program_tokens:
  if re.findall(keywords,token):
    sum += 1;


if sum <= 1:
  print("The test program cannot be generated by the simple Demo Function BNF Grammer")
else: print("The test program is generated by the BNF grammar")

